## BEYOND SALIENCY: ENHANCING EXPLANATION OF SPEECH EMOTION RECOGNITION WITH EXPERT-REFERENCED ACOUSTIC CUES

Current saliency-based methods, adapted from vision, highlight spectrogram regions but fail to show whether these regions correspond to meaningful acoustic markers of emotion, limiting faithfulness and interpretability. We propose a framework that overcomes these limitations by quantifying the magnitudes of cues within salient regions. This clarifies ‚Äúwhat‚Äù is highlighted and connects it to ‚Äúwhy‚Äù it matters, linking saliency to expert-referenced acoustic cues of speech emotions.

<img width="1782" height="1470" alt="image" src="https://github.com/user-attachments/assets/54e6e759-160d-4ac2-bbda-cdd37562f0f3" />

Experiments on benchmark SER datasets show that our approach improves explanation quality by explicitly linking salient regions to theory-driven speech emotions expert-referenced acoustics. Compared to standard saliency methods, it provides more understandable and plausible
explanations of SER models, offering a foundational step towards trustworthy speech-based affective computing.


## Quickstart

### GradCAM
```python


```



## Reproduce our results

#### 1. Install Dependencies
Make sure to install all required packages:
```bash  pip install -r src/requirements.txt ```

#### 2. Download the Datasets
Download the dataset from your chosen data source (e.g., Kaggle) and place it inside the project directory.

 #### Toronto emotional speech set (TESS)
```python
import kagglehub

# Download latest version
path = kagglehub.dataset_download("ejlok1/toronto-emotional-speech-set-tess")

print("Path to dataset files:", path)

```
#### Crowd Sourced Emotional Multimodal Actors Dataset (CREMA-D)

```python
import kagglehub

# Download latest version
path = kagglehub.dataset_download("ejlok1/cremad")

print("Path to dataset files:", path)
```
#### 3. Run data processing
Make sure to use the correct data path and provide the parameters for your dataset. Example command for the TESS dataset:

```python src/Models/SER_data.py --data_path ./TESS_df.pkl --dataset_name TESS --sample_rate 16000 ```

You can replace ```./TESS_df.pkl```, ```TESS```, and ```16000``` with your dataset‚Äôs file path, name, and sampling rate respectively.


#### 4. Run Model training
Train the model using the processed dataset; Example command for the TESS dataset:


```python src/Models/trainSER.py --df_path data/TESS_df.pkl --batch_size 32 --epochs 50 --lr 3e-4 --checkpoint src/Models/checkpoint/best_model_tess.pth```

#### 4. Run the Explanation generation
Generate the explanation of a selected dataset, XAI_methods (CRP, OS, or CRP OS ) and a selected emotions (e.g., happy sad neutral); an example command for TESS dataset:

```python -m XAI.xai_main --data_setnames Crema-D --XAI_methods GradCAM --emotions angry```

### üìÉ Citation
```
@article{
Nasr, S., Ren, Z., & Johnson, D. (2025). 
Beyond saliency: Enhancing explanation of speech emotion recognition with expert-referenced acoustic cues.
ArXiv. https://arxiv.org/abs/2511.11691
}
```
